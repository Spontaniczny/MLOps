{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-08T02:51:55.345382790Z",
     "start_time": "2026-02-08T02:51:55.337014865Z"
    }
   },
   "source": [
    "from openai import OpenAI\n",
    "from time import time"
   ],
   "outputs": [],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-08T02:56:57.866783620Z",
     "start_time": "2026-02-08T02:56:57.858054493Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def measure_time(prompts):\n",
    "    client = OpenAI(api_key=\"EMPTY\", base_url=\"http://localhost:8000/v1\")\n",
    "    start_time = time()\n",
    "    for prompt in prompts:\n",
    "        client.chat.completions.create(\n",
    "        model=\"\",\n",
    "        messages=[\n",
    "            {\"role\": \"developer\", \"content\": \"You are a helpful assistant.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt},\n",
    "        ],\n",
    "        max_completion_tokens=1000,\n",
    "        extra_body={\"chat_template_kwargs\": {\"enable_thinking\": False}}\n",
    "        )\n",
    "    return time() - start_time"
   ],
   "id": "6b80c1dd98056bac",
   "outputs": [],
   "execution_count": 24
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# those settings use vLLM server\n",
    "client = OpenAI(api_key=\"EMPTY\", base_url=\"http://localhost:8000/v1\")\n",
    "\n",
    "chat_response = client.chat.completions.create(\n",
    "    model=\"\",\n",
    "    messages=[\n",
    "        {\"role\": \"developer\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Are datascientist students a szczaw? Give me detailed answer\"},\n",
    "    ],\n",
    "    max_completion_tokens=1000,\n",
    "    extra_body={\"chat_template_kwargs\": {\"enable_thinking\": False}}\n",
    ")\n",
    "content = chat_response.choices[0].message.content.strip()\n",
    "print(\"Response:\\n\", content)"
   ],
   "id": "8ba5a1704051b391",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Exercise 1",
   "id": "baa4c45d838eb538"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Unquantized model\n",
    "vllm serve Qwen/Qwen3-0.6B --port 8000 --max-model-len 4096 --gpu-memory-utilization 0.7"
   ],
   "id": "b8223a25e49dcf07"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-08T02:51:35.812378Z",
     "start_time": "2026-02-08T02:51:35.799288779Z"
    }
   },
   "cell_type": "code",
   "source": [
    "prompts = [\n",
    "    \"How important is LLMOps on scale 0-10?\",\n",
    "    \"Jak waÅ¼ne jest LLMOps w skali 0-10?\",\n",
    "    \"What is supervised learning?\",\n",
    "    \"Co to jest uczenie ze wzmocnieniem?\",\n",
    "    \"What is the meaning of life based on spaghetti\",\n",
    "    \"(APIServer pid=91092) INFO 02-08 02:50:34 [launcher.py:46] Route: /classify, Methods: POST\",  # bcs why not?\n",
    "    \"How many R there is in RRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRPR. Find x\",\n",
    "    \"Give me 10 example prompts that I can ask you\",\n",
    "    \"Give me a seahorse emoji. Make sure that this is seahorse emoji\",\n",
    "    \"Are datascientist students a szczaw? Give me detailed answer\"\n",
    "]"
   ],
   "id": "85ce7cc0d4f88cbb",
   "outputs": [],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-08T02:57:16.370271698Z",
     "start_time": "2026-02-08T02:57:06.812352513Z"
    }
   },
   "cell_type": "code",
   "source": "measure_time(prompts)",
   "id": "81a6259961a7cbfc",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.538908958435059"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 25
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Available KV cache memory: 2.78 GiB\\\n",
    "GPU KV cache size: 25,968 tokens"
   ],
   "id": "a3dd9e06703b0a62"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Quantized model\n",
    "vllm serve Qwen/Qwen3-0.6B --port 8000 --max-model-len 4096 --gpu-memory-utilization 0.7 --quantization bitsandbytes"
   ],
   "id": "6b513c96bf83844a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-08T03:01:54.278112225Z",
     "start_time": "2026-02-08T03:01:39.765115288Z"
    }
   },
   "cell_type": "code",
   "source": "measure_time(prompts)",
   "id": "7296c8a61f85805a",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14.496115922927856"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 29
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Available KV cache memory: 3.36 GiB\\\n",
    "GPU KV cache size: 31,440 tokens"
   ],
   "id": "ea866a3cb2ba5966"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Idk why, but quantized model run slightly longer. Maybe I opened some background program?",
   "id": "fa78b06e8e0dc735"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Exercise 2",
   "id": "6f61235a3ca928a4"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-08T03:13:43.005142906Z",
     "start_time": "2026-02-08T03:13:42.986285821Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import datetime\n",
    "import json\n",
    "from typing import Callable"
   ],
   "id": "2038ccceeae6518f",
   "outputs": [],
   "execution_count": 30
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-08T03:53:24.515325577Z",
     "start_time": "2026-02-08T03:53:24.502788861Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def make_llm_request(prompt: str, tool_func=get_tool_definitions) -> str:\n",
    "    client = OpenAI(api_key=\"EMPTY\", base_url=\"http://localhost:8000/v1\")\n",
    "\n",
    "    messages = [\n",
    "        {\"role\": \"developer\", \"content\": \"You are a weather assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": prompt},\n",
    "    ]\n",
    "\n",
    "    tool_definitions, tool_name_to_func = tool_func()\n",
    "\n",
    "    # guard: loop limit, we break as soon as we get an answer\n",
    "    for _ in range(10):\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"\",\n",
    "            messages=messages,\n",
    "            tools=tool_definitions,  # always pass all tools in this example\n",
    "            tool_choice=\"auto\",\n",
    "            max_completion_tokens=1000,\n",
    "            extra_body={\"chat_template_kwargs\": {\"enable_thinking\": False}},\n",
    "        )\n",
    "        resp_message = response.choices[0].message\n",
    "        messages.append(resp_message.model_dump())\n",
    "\n",
    "        print(f\"Generated message: {resp_message.model_dump()}\")\n",
    "        print()\n",
    "\n",
    "        # parse possible tool calls (assume only \"function\" tools)\n",
    "        if resp_message.tool_calls:\n",
    "            for tool_call in resp_message.tool_calls:\n",
    "                func_name = tool_call.function.name\n",
    "                func_args = json.loads(tool_call.function.arguments)\n",
    "\n",
    "                # call tool, serialize result, append to messages\n",
    "                func = tool_name_to_func[func_name]\n",
    "                func_result = func(**func_args)\n",
    "\n",
    "                messages.append(\n",
    "                    {\n",
    "                        \"role\": \"tool\",\n",
    "                        \"content\": json.dumps(func_result),\n",
    "                        \"tool_call_id\": tool_call.id,\n",
    "                    }\n",
    "                )\n",
    "        else:\n",
    "            # no tool calls, we're done\n",
    "            return resp_message.content\n",
    "\n",
    "    # we should not get here\n",
    "    last_response = resp_message.content\n",
    "    return f\"Could not resolve request, last response: {last_response}\"\n",
    "\n",
    "\n",
    "def get_tool_definitions() -> tuple[list[dict], dict[str, Callable]]:\n",
    "    tool_definitions = [\n",
    "        {\n",
    "            \"type\": \"function\",\n",
    "            \"function\": {\n",
    "                \"name\": \"get_current_date\",\n",
    "                \"description\": 'Get current date in the format \"Year-Month-Day\" (YYYY-MM-DD).',\n",
    "                \"parameters\": {},\n",
    "            },\n",
    "        },\n",
    "        {\n",
    "            \"type\": \"function\",\n",
    "            \"function\": {\n",
    "                \"name\": \"get_weather_forecast\",\n",
    "                \"description\": \"Get weather forecast at given country, city, and date.\",\n",
    "                \"parameters\": {\n",
    "                    \"type\": \"object\",\n",
    "                    \"properties\": {\n",
    "                        \"country\": {\n",
    "                            \"type\": \"string\",\n",
    "                            \"description\": \"The country the city is in.\",\n",
    "                        },\n",
    "                        \"city\": {\n",
    "                            \"type\": \"string\",\n",
    "                            \"description\": \"The city to get the weather for.\",\n",
    "                        },\n",
    "                        \"date\": {\n",
    "                            \"type\": \"string\",\n",
    "                            \"description\": (\n",
    "                                \"The date to get the weather for, \"\n",
    "                                'in the format \"Year-Month-Day\" (YYYY-MM-DD). '\n",
    "                                \"At most 4 weeks into the future.\"\n",
    "                            ),\n",
    "                        },\n",
    "                    },\n",
    "                    \"required\": [\"country\", \"city\", \"date\"],\n",
    "                },\n",
    "            },\n",
    "        },\n",
    "    ]\n",
    "\n",
    "    tool_name_to_callable = {\n",
    "        \"get_current_date\": current_date_tool,\n",
    "        \"get_weather_forecast\": weather_forecast_tool,\n",
    "    }\n",
    "\n",
    "    return tool_definitions, tool_name_to_callable\n",
    "\n",
    "\n",
    "def current_date_tool() -> str:\n",
    "    return datetime.date.today().isoformat()\n",
    "\n",
    "\n",
    "def weather_forecast_tool(country: str, city: str, date: str) -> str:\n",
    "    if country.lower() in {\"united kingdom\", \"uk\", \"england\"}:\n",
    "        return \"Fog and rain\"\n",
    "    else:\n",
    "        return \"Sunshine\""
   ],
   "id": "cc4fc9035c87dd89",
   "outputs": [],
   "execution_count": 96
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-08T04:14:14.002932507Z",
     "start_time": "2026-02-08T04:14:13.977815930Z"
    }
   },
   "cell_type": "code",
   "source": "datetime.datetime.today().isoformat(timespec='seconds')",
   "id": "cf0eccd5c8a83714",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2026-02-08T05:14:13'"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 124
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-08T03:53:43.203693514Z",
     "start_time": "2026-02-08T03:53:42.168353823Z"
    }
   },
   "cell_type": "code",
   "source": [
    "prompt = \"What will be weather in Birmingham in two weeks?\"\n",
    "response = make_llm_request(prompt)\n",
    "print(\"Response:\\n\", response)\n",
    "\n",
    "print()\n",
    "\n",
    "prompt = \"What will be weather in Warsaw the day after tomorrow?\"\n",
    "response = make_llm_request(prompt)\n",
    "print(\"Response:\\n\", response)\n",
    "\n",
    "print()\n",
    "\n",
    "prompt = \"What will be weather in united kingdom in two months?\"\n",
    "response = make_llm_request(prompt)\n",
    "print(\"Response:\\n\", response)"
   ],
   "id": "671d8f2c87a032f6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated message: {'content': None, 'refusal': None, 'role': 'assistant', 'annotations': None, 'audio': None, 'function_call': None, 'tool_calls': [{'id': 'chatcmpl-tool-b28b6b2c920306b6', 'function': {'arguments': '{\"country\": \"Birmingham\", \"city\": \"Birmingham\", \"date\": \"YYYY-MM-DD\"}', 'name': 'get_weather_forecast'}, 'type': 'function'}], 'reasoning': None, 'reasoning_content': None}\n",
      "\n",
      "Generated message: {'content': 'The weather in Birmingham in two weeks will be Sunshine.', 'refusal': None, 'role': 'assistant', 'annotations': None, 'audio': None, 'function_call': None, 'tool_calls': [], 'reasoning': None, 'reasoning_content': None}\n",
      "\n",
      "Response:\n",
      " The weather in Birmingham in two weeks will be Sunshine.\n",
      "\n",
      "Generated message: {'content': None, 'refusal': None, 'role': 'assistant', 'annotations': None, 'audio': None, 'function_call': None, 'tool_calls': [{'id': 'chatcmpl-tool-a210675d9f490f63', 'function': {'arguments': '{\"country\": \"Warsaw\", \"city\": \"Warsaw\", \"date\": \"2023-10-23\"}', 'name': 'get_weather_forecast'}, 'type': 'function'}], 'reasoning': None, 'reasoning_content': None}\n",
      "\n",
      "Generated message: {'content': 'The weather in Warsaw the day after tomorrow will be sunshine.', 'refusal': None, 'role': 'assistant', 'annotations': None, 'audio': None, 'function_call': None, 'tool_calls': [], 'reasoning': None, 'reasoning_content': None}\n",
      "\n",
      "Response:\n",
      " The weather in Warsaw the day after tomorrow will be sunshine.\n",
      "\n",
      "Generated message: {'content': None, 'refusal': None, 'role': 'assistant', 'annotations': None, 'audio': None, 'function_call': None, 'tool_calls': [{'id': 'chatcmpl-tool-8ef89ae469953576', 'function': {'arguments': '{\"country\": \"United Kingdom\", \"city\": \"London\", \"date\": \"2023-08-01\"}', 'name': 'get_weather_forecast'}, 'type': 'function'}], 'reasoning': None, 'reasoning_content': None}\n",
      "\n",
      "Generated message: {'content': 'The weather in the United Kingdom in two months will be fog and rain.', 'refusal': None, 'role': 'assistant', 'annotations': None, 'audio': None, 'function_call': None, 'tool_calls': [], 'reasoning': None, 'reasoning_content': None}\n",
      "\n",
      "Response:\n",
      " The weather in the United Kingdom in two months will be fog and rain.\n"
     ]
    }
   ],
   "execution_count": 97
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-08T03:38:36.569358982Z",
     "start_time": "2026-02-08T03:38:36.564037392Z"
    }
   },
   "cell_type": "code",
   "source": "import polars as pl",
   "id": "c2b062e5b5ddc38",
   "outputs": [],
   "execution_count": 59
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-08T03:53:50.455168352Z",
     "start_time": "2026-02-08T03:53:50.447988866Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_tool_definitions_2():\n",
    "    tool_definitions = [\n",
    "        {\n",
    "            \"type\": \"function\",\n",
    "            \"function\": {\n",
    "                \"name\": \"read_remote_csv\",\n",
    "                \"description\": \"Read csv data under provided URL. Return n rows. Data has to be in csv format.\",\n",
    "                \"parameters\": {\n",
    "                    \"type\": \"object\",\n",
    "                    \"properties\": {\n",
    "                        \"url\": {\n",
    "                            \"type\": \"string\",\n",
    "                            \"description\": \"URL to csv file.\",\n",
    "                        },\n",
    "                        \"n\": {\n",
    "                            \"type\": \"integer\",\n",
    "                            \"description\": \"Number of rows to return.\",\n",
    "                        },\n",
    "                    },\n",
    "                    \"required\": [\"url\", \"n\"],\n",
    "                },\n",
    "            },\n",
    "        },\n",
    "\n",
    "        {\n",
    "            \"type\": \"function\",\n",
    "            \"function\": {\n",
    "                \"name\": \"read_remote_parquet\",\n",
    "                \"description\": \"Read parquet data under provided URL. Return n rows. Data has to be in parquet format.\",\n",
    "                \"parameters\": {\n",
    "                    \"type\": \"object\",\n",
    "                    \"properties\": {\n",
    "                        \"url\": {\n",
    "                            \"type\": \"string\",\n",
    "                            \"description\": \"URL to parquet file.\",\n",
    "                        },\n",
    "                        \"n\": {\n",
    "                            \"type\": \"integer\",\n",
    "                            \"description\": \"Number of rows to return.\",\n",
    "                        },\n",
    "                    },\n",
    "                    \"required\": [\"url\", \"n\"],\n",
    "                },\n",
    "            },\n",
    "        },\n",
    "    ]\n",
    "\n",
    "    tool_name_to_callable = {\n",
    "        \"read_remote_csv\": read_remote_csv,\n",
    "        \"read_remote_parquet\": read_remote_parquet\n",
    "    }\n",
    "\n",
    "    return tool_definitions, tool_name_to_callable"
   ],
   "id": "29633bde32e7eaa6",
   "outputs": [],
   "execution_count": 98
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-08T03:53:52.331178575Z",
     "start_time": "2026-02-08T03:53:52.326373045Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def read_remote_csv(url, n):\n",
    "    n = min(n, 20)\n",
    "    df = pl.read_csv(url, n_rows=n)\n",
    "    return str(df.to_dicts())\n",
    "\n",
    "def read_remote_parquet(url, n):\n",
    "    n = min(n, 20)\n",
    "    df = pl.read_parquet(url, n_rows=n)\n",
    "    return str(df.to_dicts())"
   ],
   "id": "fc6e2c27828d5f00",
   "outputs": [],
   "execution_count": 99
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-08T03:53:53.660852365Z",
     "start_time": "2026-02-08T03:53:52.509622516Z"
    }
   },
   "cell_type": "code",
   "source": [
    "morguls_csv = \"https://raw.githubusercontent.com/j-adamczyk/ApisTox_dataset/refs/heads/master/outputs/dataset_final.csv\"\n",
    "taxi_parquet = \"https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2025-01.parquet\""
   ],
   "id": "5c2e2d6fe0101ff4",
   "outputs": [],
   "execution_count": 100
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-08T03:55:33.079206900Z",
     "start_time": "2026-02-08T03:55:30.793302547Z"
    }
   },
   "cell_type": "code",
   "source": [
    "prompt = f\"Use this url to get csv data and tell me about the data you find there: {morguls_csv}\"\n",
    "response = make_llm_request(prompt, get_tool_definitions_2)\n",
    "print(\"Response:\\n\", response)"
   ],
   "id": "4b262535818b3478",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated message: {'content': None, 'refusal': None, 'role': 'assistant', 'annotations': None, 'audio': None, 'function_call': None, 'tool_calls': [{'id': 'chatcmpl-tool-8ac93ff39a0dda52', 'function': {'arguments': '{\"url\": \"https://raw.githubusercontent.com/j-adamczyk/ApisTox_dataset/refs/heads/master/outputs/dataset_final.csv\", \"n\": 5}', 'name': 'read_remote_csv'}, 'type': 'function'}], 'reasoning': None, 'reasoning_content': None}\n",
      "\n",
      "Generated message: {'content': 'Here is the data from the CSV file:\\n\\n1. **Ethanedioic acid**: CID 971, CAS 144-62-7, SMILES `O=C(O)C(=O)O`, source ECOTOX, year 1832, toxicity type Contact.\\n2. **Para-cymene**: CID 7463, CAS 99-87-6, SMILES `Cc1ccc(C(C)C)cc1`, source BPDB, year 1833, toxicity type Other.\\n3. **Kieselguhr**: CID 24261, CAS 61790-53-2, SMILES `O=[Si]=O`, source ECOTOX, year 1833, toxicity type Contact.\\n4. **Benzoic acid**: CID 243, CAS 65-85-0, SMILES `O=C(O)c1ccccc1`, source ECOTOX, year 1833, toxicity type Contact.\\n5. **Tetradifon (Ref: ENT 23737)**: CID 8305, CAS 116-29-0, SMILES `O=S(=O)(c1ccc(Cl)cc1)c1cc(Cl)c(Cl)cc1Cl`, source PPDB, year 1836, toxicity type Oral.\\n\\nEach entry provides information about the chemical compounds found in the dataset.', 'refusal': None, 'role': 'assistant', 'annotations': None, 'audio': None, 'function_call': None, 'tool_calls': [], 'reasoning': None, 'reasoning_content': None}\n",
      "\n",
      "Response:\n",
      " Here is the data from the CSV file:\n",
      "\n",
      "1. **Ethanedioic acid**: CID 971, CAS 144-62-7, SMILES `O=C(O)C(=O)O`, source ECOTOX, year 1832, toxicity type Contact.\n",
      "2. **Para-cymene**: CID 7463, CAS 99-87-6, SMILES `Cc1ccc(C(C)C)cc1`, source BPDB, year 1833, toxicity type Other.\n",
      "3. **Kieselguhr**: CID 24261, CAS 61790-53-2, SMILES `O=[Si]=O`, source ECOTOX, year 1833, toxicity type Contact.\n",
      "4. **Benzoic acid**: CID 243, CAS 65-85-0, SMILES `O=C(O)c1ccccc1`, source ECOTOX, year 1833, toxicity type Contact.\n",
      "5. **Tetradifon (Ref: ENT 23737)**: CID 8305, CAS 116-29-0, SMILES `O=S(=O)(c1ccc(Cl)cc1)c1cc(Cl)c(Cl)cc1Cl`, source PPDB, year 1836, toxicity type Oral.\n",
      "\n",
      "Each entry provides information about the chemical compounds found in the dataset.\n"
     ]
    }
   ],
   "execution_count": 104
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-08T03:56:27.590703609Z",
     "start_time": "2026-02-08T03:56:26.054651594Z"
    }
   },
   "cell_type": "code",
   "source": [
    "prompt = f\"Use this url to get parquet data and tell me about shortly about the data you find there: {taxi_parquet}\"\n",
    "response = make_llm_request(prompt, get_tool_definitions_2)\n",
    "print(\"Response:\\n\", response)"
   ],
   "id": "ffa75d3dac3c8974",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated message: {'content': None, 'refusal': None, 'role': 'assistant', 'annotations': None, 'audio': None, 'function_call': None, 'tool_calls': [{'id': 'chatcmpl-tool-ad05dacc35aa2f8a', 'function': {'arguments': '{\"url\": \"https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2025-01.parquet\", \"n\": 5}', 'name': 'read_remote_parquet'}, 'type': 'function'}], 'reasoning': None, 'reasoning_content': None}\n",
      "\n",
      "Generated message: {'content': 'Here is a summary of the parquet data:\\n\\n1. **VendorID**: The first row has a VendorID of 1.\\n2. **Pickup and Dropoff Times**: The data includes pickup and dropoff times for each trip.\\n3. **Passenger Count**: Each trip has 1 or 3 passengers.\\n4. **Trip Distance**: The distance traveled for each trip is provided.\\n5. **Rates and Other Fields**: The data includes various rates and additional details like payment type, fare, and other parameters.\\n\\nThis data appears to represent trip information from a specific date range. If you need more detailed information or further analysis, let me know!', 'refusal': None, 'role': 'assistant', 'annotations': None, 'audio': None, 'function_call': None, 'tool_calls': [], 'reasoning': None, 'reasoning_content': None}\n",
      "\n",
      "Response:\n",
      " Here is a summary of the parquet data:\n",
      "\n",
      "1. **VendorID**: The first row has a VendorID of 1.\n",
      "2. **Pickup and Dropoff Times**: The data includes pickup and dropoff times for each trip.\n",
      "3. **Passenger Count**: Each trip has 1 or 3 passengers.\n",
      "4. **Trip Distance**: The distance traveled for each trip is provided.\n",
      "5. **Rates and Other Fields**: The data includes various rates and additional details like payment type, fare, and other parameters.\n",
      "\n",
      "This data appears to represent trip information from a specific date range. If you need more detailed information or further analysis, let me know!\n"
     ]
    }
   ],
   "execution_count": 107
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "8f44ac446dfa958b"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
