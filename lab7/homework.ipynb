{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 0 ",
   "id": "4682659a26249768"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-12-01T20:54:45.659429Z",
     "start_time": "2025-12-01T20:54:45.647879Z"
    }
   },
   "source": [
    "import os.path\n",
    "from timeit import timeit\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModel"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-01T21:01:49.563580Z",
     "start_time": "2025-12-01T21:01:48.937007Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model_name = \"sentence-transformers/multi-qa-mpnet-base-cos-v1\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModel.from_pretrained(model_name)"
   ],
   "id": "ca60a334709330a6",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-01T21:17:58.496010Z",
     "start_time": "2025-12-01T21:17:58.493758Z"
    }
   },
   "cell_type": "code",
   "source": [
    "text = \"\"\"\n",
    "MiÅ‚oÅ›Ä‡ szczÄ™Å›liwa. Czy to jest normalne,\n",
    "czy to powaÅ¼ne, czy to poÅ¼yteczne -\n",
    "co Å›wiat ma z dwojga ludzi,\n",
    "ktÃ³rzy nie widzÄ… Å›wiata?\n",
    "\n",
    "WywyÅ¼szeni ku sobie bez Å¼adnej zasÅ‚ugi,\n",
    "pierwsi lepsi z miliona, ale przekonani,\n",
    "Å¼e tak staÄ‡ siÄ™ musiaÅ‚o - w nagrodÄ™ za co?\n",
    "za nic;\n",
    "Å›wiatÅ‚o pada znikÄ…d -\n",
    "dlaczego wÅ‚aÅ›nie na tych, a nie na innych?\n",
    "Czy to obraÅ¼a sprawiedliwoÅ›Ä‡? Tak.\n",
    "Czy to narusza troskliwie piÄ™trzone zasady,\n",
    "strÄ…cÄ… ze szczytu moraÅ‚? Narusza i strÄ…ca.\n",
    "\n",
    "SpÃ³jrzcie na tych szczÄ™Å›liwych:\n",
    "gdyby siÄ™ chociaÅ¼ maskowali trochÄ™,\n",
    "udawali zgnÄ™bienie krzepiÄ…c tym przyjaciÃ³Å‚!\n",
    "SÅ‚uchajcie, jak siÄ™ Å›miejÄ… - obraÅºliwie.\n",
    "Jakim jÄ™zykiem mÃ³wiÄ… - zrozumiaÅ‚ym na pozÃ³r.\n",
    "A te ich ceremonie, ceregiele,\n",
    "wymyÅ›lne obowiÄ…zki wzglÄ™dem siebie -\n",
    "wyglÄ…da to na zmowÄ™ za plecami ludzkoÅ›ci!\n",
    "\n",
    "Trudno nawet przewidzieÄ‡, do czego by doszÅ‚o,\n",
    "gdyby ich przykÅ‚ad daÅ‚ siÄ™ naÅ›ladowaÄ‡.\n",
    "Na co liczyÄ‡ by mogÅ‚y religie, poezje,\n",
    "o czym by pamiÄ™tano, czego zaniechano.\n",
    "kto by chciaÅ‚ zostaÄ‡ w krÄ™gu.\n",
    "\n",
    "MiÅ‚oÅ›Ä‡ szczÄ™Å›liwa. Czy to jest konieczne?\n",
    "Takt i rozsÄ…dek kaÅ¼Ä… milczeÄ‡ o niej\n",
    "jako skandalu z wysokich sfer Å»ycia.\n",
    "Wspaniale dziatki rodzÄ… siÄ™ bez jej pomocy.\n",
    "Przenigdy nie zdolaÅ‚aby zaludniÄ‡ ziemi,\n",
    "zdarza siÄ™ przecieÅ¼ rzadko.\n",
    "\n",
    "Niech ludzie nie znajÄ…cy miÅ‚oÅ›ci szczÄ™Å›liwej\n",
    "twierdzÄ…, Å¼e nigdzie nie ma miÅ‚oÅ›ci szczÄ™Å›liwej.\n",
    "\n",
    "Z tÄ… wiarÄ… lÅ¼ej im bÄ™dzie i Å¼yÄ‡, i umieraÄ‡.\"\"\"\n",
    "\n",
    "#  ÅºrÃ³dÅ‚o: https://poezja.org/wz/Wislawa_Szymborska/19/Milosc_szczesliwa"
   ],
   "id": "37804f75ff97778a",
   "outputs": [],
   "execution_count": 35
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-01T21:21:14.533595Z",
     "start_time": "2025-12-01T21:21:14.531176Z"
    }
   },
   "cell_type": "code",
   "source": "encoded_input = tokenizer(text, padding=True, truncation=True, return_tensors=\"pt\")",
   "id": "d29a223cd9d6081e",
   "outputs": [],
   "execution_count": 44
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-01T21:42:58.861760Z",
     "start_time": "2025-12-01T21:42:58.860294Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import timeit\n",
    "import torch\n"
   ],
   "id": "615a9f1705245ba7",
   "outputs": [],
   "execution_count": 52
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 1",
   "id": "36a8ec8a3cb87a56"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-01T21:50:17.799461Z",
     "start_time": "2025-12-01T21:50:17.797341Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def no_optimizations():\n",
    "    model.train()\n",
    "    _ = model(**encoded_input)\n",
    "\n",
    "\n",
    "def only_eval():\n",
    "    model.eval()\n",
    "    _ = model(**encoded_input)\n",
    "\n",
    "\n",
    "def eval_no_grad():\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        _ = model(**encoded_input)\n",
    "\n",
    "def eval_inference():\n",
    "    model.eval()\n",
    "    with torch.inference_mode():\n",
    "        _ = model(**encoded_input)"
   ],
   "id": "54ff23d627f85ad8",
   "outputs": [],
   "execution_count": 53
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-01T21:56:30.283857Z",
     "start_time": "2025-12-01T21:55:38.916273Z"
    }
   },
   "cell_type": "code",
   "source": [
    "n_runs = 100\n",
    "\n",
    "no_opti_avg_time = timeit.timeit(no_optimizations, number=n_runs) / n_runs\n",
    "only_eval_avg_time = timeit.timeit(only_eval, number=n_runs) / n_runs\n",
    "eval_no_grad_avg_time = timeit.timeit(eval_no_grad, number=n_runs) / n_runs\n",
    "eval_inference_avg_time = timeit.timeit(eval_inference, number=n_runs) / n_runs"
   ],
   "id": "a1e7bafc9743022c",
   "outputs": [],
   "execution_count": 54
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-01T21:56:34.712590Z",
     "start_time": "2025-12-01T21:56:34.710544Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"Benchmark results:\")\n",
    "print(f\"{no_opti_avg_time=:.6f}\")\n",
    "print(f\"{only_eval_avg_time=:.6f}\")\n",
    "print(f\"{eval_no_grad_avg_time=:.6f}\")\n",
    "print(f\"{eval_inference_avg_time=:.6f}\")"
   ],
   "id": "642309fa9a693bf6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Benchmark results:\n",
      "no_opti_avg_time=0.142580\n",
      "only_eval_avg_time=0.125754\n",
      "eval_no_grad_avg_time=0.123940\n",
      "eval_inference_avg_time=0.121378\n"
     ]
    }
   ],
   "execution_count": 55
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-01T21:58:44.018976Z",
     "start_time": "2025-12-01T21:58:44.017138Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"Speedup comparing to no optimization method\")\n",
    "print(f\"{no_opti_avg_time / only_eval_avg_time:.2f}\")\n",
    "print(f\"{no_opti_avg_time / eval_no_grad_avg_time:.2f}\")\n",
    "print(f\"{no_opti_avg_time / eval_inference_avg_time:.2f}\")"
   ],
   "id": "5106d4c3cecc5568",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speedup comparing to no optimization method\n",
      "1.13\n",
      "1.15\n",
      "1.17\n"
     ]
    }
   ],
   "execution_count": 57
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 2",
   "id": "3bc1059d29485db1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-01T22:09:38.059579Z",
     "start_time": "2025-12-01T22:09:38.057914Z"
    }
   },
   "cell_type": "code",
   "source": "from time import time",
   "id": "f3c81f6bb157d32c",
   "outputs": [],
   "execution_count": 59
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-01T22:11:12.247293Z",
     "start_time": "2025-12-01T22:10:59.875978Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model.eval()\n",
    "\n",
    "start_time = time()\n",
    "\n",
    "compiled_model = torch.compile(model)\n",
    "_ = compiled_model(**encoded_input)\n",
    "\n",
    "end_time = time() - start_time\n",
    "\n",
    "print(f\"Total time of compilation and warmup inference: {end_time:.6f}\")"
   ],
   "id": "732182ae84b50dda",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time of compilation and warmup inference: 12.368721\n"
     ]
    }
   ],
   "execution_count": 60
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-01T22:12:37.911959Z",
     "start_time": "2025-12-01T22:12:37.910316Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def compiled_eval_inference():\n",
    "    with torch.inference_mode():\n",
    "        _ = compiled_model(**encoded_input)"
   ],
   "id": "ffc82248d9185902",
   "outputs": [],
   "execution_count": 64
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-01T22:13:17.743508Z",
     "start_time": "2025-12-01T22:13:05.730762Z"
    }
   },
   "cell_type": "code",
   "source": "compiled_eval_inference_avg_time = timeit.timeit(compiled_eval_inference, number=n_runs) / n_runs",
   "id": "7735378bd86b3ad4",
   "outputs": [],
   "execution_count": 66
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-01T22:13:25.248027Z",
     "start_time": "2025-12-01T22:13:25.246048Z"
    }
   },
   "cell_type": "code",
   "source": "print(f\"{compiled_eval_inference_avg_time=:.6f}\")",
   "id": "a4861d2f67b59914",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compiled_eval_inference_avg_time=0.120110\n"
     ]
    }
   ],
   "execution_count": 67
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-01T22:13:47.857589Z",
     "start_time": "2025-12-01T22:13:47.855804Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"Speedup comparing to no optimization method\")\n",
    "print(f\"{no_opti_avg_time / compiled_eval_inference_avg_time:.2f}\")"
   ],
   "id": "33f26248803af74b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speedup comparing to no optimization method\n",
      "1.19\n"
     ]
    }
   ],
   "execution_count": 68
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Yes. This is the best so far! ðŸ’…ðŸ’… (this is Kuba, no LLM here)",
   "id": "fb83241a8b90b4bd"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 3",
   "id": "6135607a49ace60b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-01T22:45:53.631181Z",
     "start_time": "2025-12-01T22:45:53.628763Z"
    }
   },
   "cell_type": "code",
   "source": "model = model.to(\"cpu\")",
   "id": "d3713608a2d4207",
   "outputs": [],
   "execution_count": 69
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-01T22:52:01.203122Z",
     "start_time": "2025-12-01T22:52:00.839183Z"
    }
   },
   "cell_type": "code",
   "source": "model_quantized = torch.ao.quantization.quantize_dynamic(model, dtype=torch.qint8)",
   "id": "3ea98135f8bcbf47",
   "outputs": [],
   "execution_count": 72
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-01T22:52:12.824373Z",
     "start_time": "2025-12-01T22:52:12.701086Z"
    }
   },
   "cell_type": "code",
   "source": "print(model_quantized)",
   "id": "d67e300ff0b27dc1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MPNetModel(\n",
      "  (embeddings): MPNetEmbeddings(\n",
      "    (word_embeddings): Embedding(30527, 768, padding_idx=1)\n",
      "    (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
      "    (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (encoder): MPNetEncoder(\n",
      "    (layer): ModuleList(\n",
      "      (0-11): 12 x MPNetLayer(\n",
      "        (attention): MPNetAttention(\n",
      "          (attn): MPNetSelfAttention(\n",
      "            (q): DynamicQuantizedLinear(in_features=768, out_features=768, dtype=torch.qint8, qscheme=torch.per_tensor_affine)\n",
      "            (k): DynamicQuantizedLinear(in_features=768, out_features=768, dtype=torch.qint8, qscheme=torch.per_tensor_affine)\n",
      "            (v): DynamicQuantizedLinear(in_features=768, out_features=768, dtype=torch.qint8, qscheme=torch.per_tensor_affine)\n",
      "            (o): DynamicQuantizedLinear(in_features=768, out_features=768, dtype=torch.qint8, qscheme=torch.per_tensor_affine)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (intermediate): MPNetIntermediate(\n",
      "          (dense): DynamicQuantizedLinear(in_features=768, out_features=3072, dtype=torch.qint8, qscheme=torch.per_tensor_affine)\n",
      "          (intermediate_act_fn): GELUActivation()\n",
      "        )\n",
      "        (output): MPNetOutput(\n",
      "          (dense): DynamicQuantizedLinear(in_features=3072, out_features=768, dtype=torch.qint8, qscheme=torch.per_tensor_affine)\n",
      "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (relative_attention_bias): Embedding(32, 12)\n",
      "  )\n",
      "  (pooler): MPNetPooler(\n",
      "    (dense): DynamicQuantizedLinear(in_features=768, out_features=768, dtype=torch.qint8, qscheme=torch.per_tensor_affine)\n",
      "    (activation): Tanh()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "execution_count": 73
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-01T22:53:28.713140Z",
     "start_time": "2025-12-01T22:53:28.398009Z"
    }
   },
   "cell_type": "code",
   "source": "torch.save(model.state_dict(), \"model.pth\")",
   "id": "6acbb1545c43be78",
   "outputs": [],
   "execution_count": 74
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-01T22:53:36.787298Z",
     "start_time": "2025-12-01T22:53:36.553967Z"
    }
   },
   "cell_type": "code",
   "source": "torch.save(model_quantized.state_dict(), \"model_quantized.pth\")",
   "id": "2484da844d0c504f",
   "outputs": [],
   "execution_count": 75
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-01T22:56:43.309609Z",
     "start_time": "2025-12-01T22:56:43.307635Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(f\"Size of normal model: {os.path.getsize('model.pth') / 1024 / 1024:.5} MB\")\n",
    "print(f\"Size of model quantized: {os.path.getsize('model_quantized.pth') / 1024 / 1024:.5} MB\")"
   ],
   "id": "5aecfc3ad69a57f1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of normal model: 417.72 MB\n",
      "Size of model quantized: 173.1 MB\n"
     ]
    }
   ],
   "execution_count": 83
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "953b6b8ee25b51be"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
